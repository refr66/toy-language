//! MLIR text emitter
//!
//! Generates SSA-compliant MLIR dialect representation of sBPF programs.
//! Uses memref.alloca for register file to avoid SSA conflicts.

use std::fmt::Write;
use crate::ir::{SbpfProgram, Function, BasicBlock, SbpfInsn, AluOp, MemSize, CallTarget, Operand, JmpCond};

/// MLIR emitter for sBPF programs
pub struct MlirEmitter;

/// State for SSA value generation
struct EmitState {
    /// Counter for generating unique SSA values
    ssa_counter: usize,
}

impl EmitState {
    fn new() -> Self {
        Self { ssa_counter: 0 }
    }
    
    fn next_ssa(&mut self) -> usize {
        let v = self.ssa_counter;
        self.ssa_counter += 1;
        v
    }
}

impl MlirEmitter {
    /// Emit MLIR module for a program
    pub fn emit_program(program: &SbpfProgram) -> String {
        let mut mlir = String::new();
        
        writeln!(mlir, "// MLIR representation of sBPF program").unwrap();
        writeln!(mlir, "// Generated by sbpf-frontend").unwrap();
        writeln!(mlir, "// Using memref.alloca for SSA-compliant register file").unwrap();
        writeln!(mlir).unwrap();
        writeln!(mlir, "module {{").unwrap();
        
        // Emit each function as independent func.func
        for func in program.functions.values() {
            let func_mlir = Self::emit_function(func, &program.entrypoint);
            for line in func_mlir.lines() {
                writeln!(mlir, "  {}", line).unwrap();
            }
            writeln!(mlir).unwrap();
        }
        
        writeln!(mlir, "}}").unwrap();
        mlir
    }
    
    /// Emit MLIR function with proper SSA semantics
    pub fn emit_function(func: &Function, entrypoint: &str) -> String {
        let mut mlir = String::new();
        let mut state = EmitState::new();
        
        let is_entry = func.name == entrypoint;
        let mangled_name = Self::mangle_name(&func.name);
        
        // Function signature:
        // - Entry: @entrypoint(%arg0: i64) -> i64  (r1 = input context)
        // - Internal: @func_name(%r1: i64, %r2: i64, ...) -> i64
        if is_entry {
            writeln!(mlir, "// Entry point function").unwrap();
            writeln!(mlir, "func.func @{}(%arg0: i64) -> i64 {{", mangled_name).unwrap();
        } else {
            writeln!(mlir, "// Internal function: {}", func.name).unwrap();
            writeln!(mlir, "func.func @{}(%arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64) -> i64 {{", mangled_name).unwrap();
        }
        
        // Allocate register file using memref.alloca (one per register r0-r10)
        writeln!(mlir, "  // ========== Register File Allocation ==========").unwrap();
        writeln!(mlir, "  // Registers r0-r10 as memory locations to maintain SSA").unwrap();
        for i in 0..=10 {
            writeln!(mlir, "  %reg{} = memref.alloca() : memref<i64>", i).unwrap();
        }
        writeln!(mlir).unwrap();
        
        // Initialize registers
        writeln!(mlir, "  // ========== Register Initialization ==========").unwrap();
        let zero_ssa = state.next_ssa();
        writeln!(mlir, "  %c0_{} = arith.constant 0 : i64", zero_ssa).unwrap();
        
        // r0 = 0 (return value)
        writeln!(mlir, "  memref.store %c0_{}, %reg0[] : memref<i64>  // r0 = 0 (return)", zero_ssa).unwrap();
        
        // r1 = input argument
        if is_entry {
            writeln!(mlir, "  memref.store %arg0, %reg1[] : memref<i64>  // r1 = input context").unwrap();
        } else {
            writeln!(mlir, "  memref.store %arg1, %reg1[] : memref<i64>  // r1 = arg1").unwrap();
            writeln!(mlir, "  memref.store %arg2, %reg2[] : memref<i64>  // r2 = arg2").unwrap();
            writeln!(mlir, "  memref.store %arg3, %reg3[] : memref<i64>  // r3 = arg3").unwrap();
            writeln!(mlir, "  memref.store %arg4, %reg4[] : memref<i64>  // r4 = arg4").unwrap();
            writeln!(mlir, "  memref.store %arg5, %reg5[] : memref<i64>  // r5 = arg5").unwrap();
        }
        
        // r6-r9 = 0 (callee-saved)
        for i in 6..=9 {
            writeln!(mlir, "  memref.store %c0_{}, %reg{}[] : memref<i64>  // r{} = 0 (callee-saved)", zero_ssa, i, i).unwrap();
        }
        
        // r10 = stack pointer (use a symbolic constant)
        let stack_ptr_ssa = state.next_ssa();
        writeln!(mlir, "  %stack_base_{} = arith.constant 0x200000000 : i64  // Stack base", stack_ptr_ssa).unwrap();
        writeln!(mlir, "  memref.store %stack_base_{}, %reg10[] : memref<i64>  // r10 = stack pointer", stack_ptr_ssa).unwrap();
        writeln!(mlir).unwrap();
        
        // Branch to entry block
        if let Some(entry_block) = func.blocks.values().next() {
            writeln!(mlir, "  cf.br ^bb{}", entry_block.id).unwrap();
        }
        writeln!(mlir).unwrap();
        
        // Emit basic blocks
        writeln!(mlir, "  // ========== Basic Blocks ==========").unwrap();
        let block_ids: Vec<usize> = func.blocks.keys().copied().collect();
        
        for (idx, block) in func.blocks.values().enumerate() {
            let next_block = if idx + 1 < block_ids.len() {
                Some(block_ids[idx + 1])
            } else {
                None
            };
            Self::emit_block(&mut mlir, block, &mut state, next_block);
        }
        
        writeln!(mlir, "}}").unwrap();
        mlir
    }
    
    /// Emit a basic block
    fn emit_block(mlir: &mut String, block: &BasicBlock, state: &mut EmitState, next_block: Option<usize>) {
        writeln!(mlir, "^bb{}:  // {}", block.id, block.label).unwrap();
        
        let mut needs_terminator = true;
        
        for (idx, (pc, insn)) in block.instructions.iter().enumerate() {
            let is_last = idx == block.instructions.len() - 1;
            writeln!(mlir, "  // PC {:04x}: {}", pc, insn).unwrap();
            Self::emit_instruction(mlir, insn, state, is_last, next_block);
            
            // Check if this instruction is a terminator
            if is_last {
                needs_terminator = !Self::is_terminator(insn);
            }
        }
        
        // Add fallthrough branch if block doesn't end with a terminator
        if needs_terminator {
            if let Some(next) = next_block {
                writeln!(mlir, "  cf.br ^bb{}  // fallthrough", next).unwrap();
            } else {
                // No next block - return 0 as default
                let v_ret = state.next_ssa();
                writeln!(mlir, "  %default_ret_{} = memref.load %reg0[] : memref<i64>", v_ret).unwrap();
                writeln!(mlir, "  func.return %default_ret_{} : i64  // implicit return", v_ret).unwrap();
            }
        }
        
        writeln!(mlir).unwrap();
    }
    
    /// Check if an instruction is a terminator (ends a basic block)
    fn is_terminator(insn: &SbpfInsn) -> bool {
        matches!(insn, 
            SbpfInsn::Jump { .. } | 
            SbpfInsn::JumpCond { .. } | 
            SbpfInsn::Exit
        )
    }
    
    /// Emit single instruction as MLIR operations
    fn emit_instruction(mlir: &mut String, insn: &SbpfInsn, state: &mut EmitState, is_last: bool, next_block: Option<usize>) {
        match insn {
            SbpfInsn::LoadImm64 { dst, imm } => {
                let v = state.next_ssa();
                writeln!(mlir, "  %imm_{} = arith.constant {} : i64", v, imm).unwrap();
                writeln!(mlir, "  memref.store %imm_{}, %reg{}[] : memref<i64>", v, dst.0).unwrap();
            }
            
            SbpfInsn::Load { dst, src, off, size } => {
                let bits = Self::memsize_to_bits(size);
                let v_base = state.next_ssa();
                let v_result = state.next_ssa();
                
                writeln!(mlir, "  %base_{} = memref.load %reg{}[] : memref<i64>", v_base, src.0).unwrap();
                
                let addr_val = if *off != 0 {
                    let v_off = state.next_ssa();
                    let v_addr = state.next_ssa();
                    writeln!(mlir, "  %off_{} = arith.constant {} : i64", v_off, *off as i64).unwrap();
                    writeln!(mlir, "  %addr_{} = arith.addi %base_{}, %off_{} : i64", v_addr, v_base, v_off).unwrap();
                    format!("%addr_{}", v_addr)
                } else {
                    format!("%base_{}", v_base)
                };
                
                writeln!(mlir, "  %val_{} = sbpf.load {} : i{}", v_result, addr_val, bits).unwrap();
                
                // Zero-extend if needed
                if bits < 64 {
                    let v_ext = state.next_ssa();
                    writeln!(mlir, "  %ext_{} = arith.extui %val_{} : i{} to i64", v_ext, v_result, bits).unwrap();
                    writeln!(mlir, "  memref.store %ext_{}, %reg{}[] : memref<i64>", v_ext, dst.0).unwrap();
                } else {
                    writeln!(mlir, "  memref.store %val_{}, %reg{}[] : memref<i64>", v_result, dst.0).unwrap();
                }
            }
            
            SbpfInsn::StoreImm { dst, off, imm, size } => {
                let bits = Self::memsize_to_bits(size);
                let v_base = state.next_ssa();
                let v_imm = state.next_ssa();
                
                writeln!(mlir, "  %base_{} = memref.load %reg{}[] : memref<i64>", v_base, dst.0).unwrap();
                
                if *off != 0 {
                    let v_off = state.next_ssa();
                    let v_addr = state.next_ssa();
                    writeln!(mlir, "  %off_{} = arith.constant {} : i64", v_off, *off as i64).unwrap();
                    writeln!(mlir, "  %addr_{} = arith.addi %base_{}, %off_{} : i64", v_addr, v_base, v_off).unwrap();
                    writeln!(mlir, "  %imm_{} = arith.constant {} : i{}", v_imm, imm, bits).unwrap();
                    writeln!(mlir, "  sbpf.store %addr_{}, %imm_{} : i{}", v_addr, v_imm, bits).unwrap();
                } else {
                    writeln!(mlir, "  %imm_{} = arith.constant {} : i{}", v_imm, imm, bits).unwrap();
                    writeln!(mlir, "  sbpf.store %base_{}, %imm_{} : i{}", v_base, v_imm, bits).unwrap();
                }
            }
            
            SbpfInsn::StoreReg { dst, off, src, size } => {
                let bits = Self::memsize_to_bits(size);
                let v_base = state.next_ssa();
                let v_src = state.next_ssa();
                
                writeln!(mlir, "  %base_{} = memref.load %reg{}[] : memref<i64>", v_base, dst.0).unwrap();
                writeln!(mlir, "  %src_{} = memref.load %reg{}[] : memref<i64>", v_src, src.0).unwrap();
                
                if *off != 0 {
                    let v_off = state.next_ssa();
                    let v_addr = state.next_ssa();
                    writeln!(mlir, "  %off_{} = arith.constant {} : i64", v_off, *off as i64).unwrap();
                    writeln!(mlir, "  %addr_{} = arith.addi %base_{}, %off_{} : i64", v_addr, v_base, v_off).unwrap();
                    
                    if bits < 64 {
                        let v_trunc = state.next_ssa();
                        writeln!(mlir, "  %trunc_{} = arith.trunci %src_{} : i64 to i{}", v_trunc, v_src, bits).unwrap();
                        writeln!(mlir, "  sbpf.store %addr_{}, %trunc_{} : i{}", v_addr, v_trunc, bits).unwrap();
                    } else {
                        writeln!(mlir, "  sbpf.store %addr_{}, %src_{} : i{}", v_addr, v_src, bits).unwrap();
                    }
                } else {
                    if bits < 64 {
                        let v_trunc = state.next_ssa();
                        writeln!(mlir, "  %trunc_{} = arith.trunci %src_{} : i64 to i{}", v_trunc, v_src, bits).unwrap();
                        writeln!(mlir, "  sbpf.store %base_{}, %trunc_{} : i{}", v_base, v_trunc, bits).unwrap();
                    } else {
                        writeln!(mlir, "  sbpf.store %base_{}, %src_{} : i{}", v_base, v_src, bits).unwrap();
                    }
                }
            }
            
            SbpfInsn::Alu64 { op, dst, src } => {
                Self::emit_alu(mlir, op, dst.0, src, 64, state);
            }
            
            SbpfInsn::Alu32 { op, dst, src } => {
                Self::emit_alu(mlir, op, dst.0, src, 32, state);
            }
            
            SbpfInsn::Jump { target } => {
                writeln!(mlir, "  cf.br ^bb{}", target).unwrap();
            }
            
            SbpfInsn::JumpCond { cond, dst, src, target } => {
                let cmp = Self::jmpcond_to_cmp(cond);
                let v_dst = state.next_ssa();
                let v_cond = state.next_ssa();
                
                writeln!(mlir, "  %dst_{} = memref.load %reg{}[] : memref<i64>", v_dst, dst.0).unwrap();
                
                match src {
                    Operand::Reg(r) => {
                        let v_src = state.next_ssa();
                        writeln!(mlir, "  %src_{} = memref.load %reg{}[] : memref<i64>", v_src, r.0).unwrap();
                        writeln!(mlir, "  %cond_{} = arith.cmpi {}, %dst_{}, %src_{} : i64", v_cond, cmp, v_dst, v_src).unwrap();
                    }
                    Operand::Imm(i) => {
                        let v_imm = state.next_ssa();
                        writeln!(mlir, "  %imm_{} = arith.constant {} : i64", v_imm, i).unwrap();
                        writeln!(mlir, "  %cond_{} = arith.cmpi {}, %dst_{}, %imm_{} : i64", v_cond, cmp, v_dst, v_imm).unwrap();
                    }
                }
                
                // Fallthrough to next block
                let fallthrough = next_block.unwrap_or(*target + 1);
                writeln!(mlir, "  cf.cond_br %cond_{}, ^bb{}, ^bb{}", v_cond, target, fallthrough).unwrap();
            }
            
            SbpfInsn::Call { target } => {
                // Load arguments r1-r5
                let v_args: Vec<usize> = (1..=5).map(|_| state.next_ssa()).collect();
                for (i, v) in v_args.iter().enumerate() {
                    writeln!(mlir, "  %arg{}_{} = memref.load %reg{}[] : memref<i64>", i+1, v, i+1).unwrap();
                }
                
                let v_result = state.next_ssa();
                match target {
                    CallTarget::Internal { name: Some(ref name), .. } => {
                        writeln!(mlir, "  %ret_{} = func.call @{}(%arg1_{}, %arg2_{}, %arg3_{}, %arg4_{}, %arg5_{}) : (i64, i64, i64, i64, i64) -> i64", 
                                 v_result, Self::mangle_name(name), v_args[0], v_args[1], v_args[2], v_args[3], v_args[4]).unwrap();
                    }
                    CallTarget::Internal { pc, .. } => {
                        writeln!(mlir, "  %ret_{} = func.call @function_{}(%arg1_{}, %arg2_{}, %arg3_{}, %arg4_{}, %arg5_{}) : (i64, i64, i64, i64, i64) -> i64", 
                                 v_result, pc, v_args[0], v_args[1], v_args[2], v_args[3], v_args[4]).unwrap();
                    }
                    CallTarget::Syscall { name: Some(ref name), .. } => {
                        writeln!(mlir, "  %ret_{} = sbpf.syscall @{}(%arg1_{}, %arg2_{}, %arg3_{}, %arg4_{}, %arg5_{}) : (i64, i64, i64, i64, i64) -> i64", 
                                 v_result, Self::mangle_name(name), v_args[0], v_args[1], v_args[2], v_args[3], v_args[4]).unwrap();
                    }
                    CallTarget::Syscall { hash, .. } => {
                        writeln!(mlir, "  %ret_{} = sbpf.syscall_hash 0x{:08x}(%arg1_{}, %arg2_{}, %arg3_{}, %arg4_{}, %arg5_{}) : (i64, i64, i64, i64, i64) -> i64", 
                                 v_result, hash, v_args[0], v_args[1], v_args[2], v_args[3], v_args[4]).unwrap();
                    }
                    CallTarget::Register(r) => {
                        let v_target = state.next_ssa();
                        writeln!(mlir, "  %target_{} = memref.load %reg{}[] : memref<i64>", v_target, r.0).unwrap();
                        writeln!(mlir, "  %ret_{} = sbpf.call_indirect %target_{}(%arg1_{}, %arg2_{}, %arg3_{}, %arg4_{}, %arg5_{}) : (i64, i64, i64, i64, i64, i64) -> i64", 
                                 v_result, v_target, v_args[0], v_args[1], v_args[2], v_args[3], v_args[4]).unwrap();
                    }
                }
                writeln!(mlir, "  memref.store %ret_{}, %reg0[] : memref<i64>  // r0 = return value", v_result).unwrap();
                
                // If not the last instruction in block, continue
                if !is_last {
                    // No branch needed, fall through
                }
            }
            
            SbpfInsn::Exit => {
                let v_ret = state.next_ssa();
                writeln!(mlir, "  %ret_{} = memref.load %reg0[] : memref<i64>", v_ret).unwrap();
                writeln!(mlir, "  func.return %ret_{} : i64", v_ret).unwrap();
            }
            
            SbpfInsn::Endian { dst, size, to_le } => {
                let v_val = state.next_ssa();
                let v_result = state.next_ssa();
                let op = if *to_le { "le" } else { "be" };
                
                writeln!(mlir, "  %val_{} = memref.load %reg{}[] : memref<i64>", v_val, dst.0).unwrap();
                writeln!(mlir, "  %res_{} = sbpf.{}{} %val_{} : i64", v_result, op, size, v_val).unwrap();
                writeln!(mlir, "  memref.store %res_{}, %reg{}[] : memref<i64>", v_result, dst.0).unwrap();
            }
            
            SbpfInsn::Unknown { raw } => {
                writeln!(mlir, "  // Unknown opcode 0x{:02x} - skipped", raw.opc).unwrap();
            }
        }
    }
    
    /// Emit ALU operation with proper SSA
    fn emit_alu(mlir: &mut String, op: &AluOp, dst: u8, src: &Operand, bits: u8, state: &mut EmitState) {
        let v_dst = state.next_ssa();
        let v_result = state.next_ssa();
        
        writeln!(mlir, "  %dst_{} = memref.load %reg{}[] : memref<i64>", v_dst, dst).unwrap();
        
        // Truncate to 32-bit if needed
        let dst_val = if bits == 32 {
            let v_trunc = state.next_ssa();
            writeln!(mlir, "  %trunc_{} = arith.trunci %dst_{} : i64 to i32", v_trunc, v_dst).unwrap();
            format!("%trunc_{}", v_trunc)
        } else {
            format!("%dst_{}", v_dst)
        };
        
        // Get source value
        let src_val = match src {
            Operand::Reg(r) => {
                let v_src = state.next_ssa();
                writeln!(mlir, "  %src_{} = memref.load %reg{}[] : memref<i64>", v_src, r.0).unwrap();
                if bits == 32 {
                    let v_trunc = state.next_ssa();
                    writeln!(mlir, "  %srct_{} = arith.trunci %src_{} : i64 to i32", v_trunc, v_src).unwrap();
                    format!("%srct_{}", v_trunc)
                } else {
                    format!("%src_{}", v_src)
                }
            }
            Operand::Imm(i) => {
                let v_imm = state.next_ssa();
                writeln!(mlir, "  %imm_{} = arith.constant {} : i{}", v_imm, i, bits).unwrap();
                format!("%imm_{}", v_imm)
            }
        };
        
        // Perform operation
        let result_val = match op {
            AluOp::Mov => {
                // Special case: just use source directly
                src_val.clone()
            }
            AluOp::Neg => {
                let v_zero = state.next_ssa();
                writeln!(mlir, "  %zero_{} = arith.constant 0 : i{}", v_zero, bits).unwrap();
                writeln!(mlir, "  %neg_{} = arith.subi %zero_{}, {} : i{}", v_result, v_zero, dst_val, bits).unwrap();
                format!("%neg_{}", v_result)
            }
            _ => {
                let arith_op = match op {
                    AluOp::Add => "arith.addi",
                    AluOp::Sub => "arith.subi",
                    AluOp::Mul => "arith.muli",
                    AluOp::Div => "arith.divui",
                    AluOp::Mod => "arith.remui",
                    AluOp::Or => "arith.ori",
                    AluOp::And => "arith.andi",
                    AluOp::Xor => "arith.xori",
                    AluOp::Lsh => "arith.shli",
                    AluOp::Rsh => "arith.shrui",
                    AluOp::Arsh => "arith.shrsi",
                    _ => unreachable!(),
                };
                writeln!(mlir, "  %res_{} = {} {}, {} : i{}", v_result, arith_op, dst_val, src_val, bits).unwrap();
                format!("%res_{}", v_result)
            }
        };
        
        // Zero-extend 32-bit result to 64-bit and store
        if bits == 32 {
            let v_ext = state.next_ssa();
            writeln!(mlir, "  %ext_{} = arith.extui {} : i32 to i64", v_ext, result_val).unwrap();
            writeln!(mlir, "  memref.store %ext_{}, %reg{}[] : memref<i64>", v_ext, dst).unwrap();
        } else {
            writeln!(mlir, "  memref.store {}, %reg{}[] : memref<i64>", result_val, dst).unwrap();
        }
    }
    
    /// Convert MemSize to bit width
    fn memsize_to_bits(size: &MemSize) -> u8 {
        match size {
            MemSize::Byte => 8,
            MemSize::Half => 16,
            MemSize::Word => 32,
            MemSize::DoubleWord => 64,
        }
    }
    
    /// Convert JmpCond to MLIR comparison predicate
    fn jmpcond_to_cmp(cond: &JmpCond) -> &'static str {
        match cond {
            JmpCond::Eq => "eq",
            JmpCond::Ne => "ne",
            JmpCond::Gt => "ugt",
            JmpCond::Ge => "uge",
            JmpCond::Lt => "ult",
            JmpCond::Le => "ule",
            JmpCond::Sgt => "sgt",
            JmpCond::Sge => "sge",
            JmpCond::Slt => "slt",
            JmpCond::Sle => "sle",
            JmpCond::Set => "ne", // x & y != 0
        }
    }
    
    /// Mangle function name for MLIR
    fn mangle_name(name: &str) -> String {
        name.chars()
            .map(|c| if c.is_alphanumeric() || c == '_' { c } else { '_' })
            .collect()
    }
}
